\chapter{Evaluation}
\label{chap:evaluation}

In this chapter, we experimentally evaluate the our implementation of the framework discussed in \crefrange{chap:visualizing-static-input-graphs}{chap:visualizing-dynamic-input-graphs} in order to gain insights into areas that may need to be improved upon in future research.
As part of our evaluation, we give answers to the following research questions:

\begin{enumerate}
	\item Which quality metrics best capture the accuracy of the maps generated by our algorithm in terms of
	\begin{enumerate}
	\item accuracy?
	\item our understanding of locally fat regions?
	\end{enumerate}
	\item What is the quality of the maps generated by our algorithm according to these quality metrics?
	\begin{enumerate}
	\item How does this quality change based on the size and other properties of the input graph?
	\item How does this quality change over time as dynamic updates are incorporated?
	\end{enumerate}
\end{enumerate}

First, we discuss a variety of possible quality metrics from literature and how they can be applied to our framework in \cref{sect:quality-metrics}.
We pick two metrics to proceed with that best capture the quality of the generated maps according to research question 1.
In \cref{sect:test-case-generation} we present the algorithm we use to generate randomized test instances to perform our experimental evaluation with.
Eventually, in \crefrange{sect:implementation-and-experiment-setup}{sect:experimental-evaluation}, we conduct the actual experimental evaluation on a large number of test instances and see how the maps generated by our algorithm perform, thereby answering research question 2.

\input{Sources/05-01-Quality-Metrics.tex}
\clearpage
\input{Sources/05-02-Test-Case-Generation.tex}
\clearpage
\input{Sources/05-03-Implementation-and-Experiment-Setup.tex}
\clearpage
\input{Sources/05-04-Experimental-Evaluation.tex}
